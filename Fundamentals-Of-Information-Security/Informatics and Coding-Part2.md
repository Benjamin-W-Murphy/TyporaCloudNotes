# Informatics and Coding-Part2

## 4 信息率失真函数

### 4.1 信息率失真函数的性质和概念

问题：信号在传输过程中存在的一定失真是可以容忍的，但需要规定一个失真限度，以保证信息在失真后仍有可用性

#### 4.1.1 失真函数和平均失真

假设存在信源X，输出样值为$x_i,x_i \in \{a_1,a_2,\cdots,a_n\}$，经过有失真的信源编码器，输出Y，样值为$y_j,y_j \in \{b_1,b_2,\cdots,b_m\}$

- 如果$x_i =y_j$则信息没有失真；如果$x_i \neq y_j$就产生了失真

- 此时失真的大小需要用一个**失真函数**表示，即$d(x_i,y_j)$，衡量用$y_j$代替$x_i$所引起的失真程度

- 失真函数定义为
  $$
  d(x_i,y_j)= \begin{cases}
  0\;\;,x_i=y_j \\
  \alpha \;\;,\alpha >0,x_i \neq y_j
  \end{cases}
  $$
  此时将所有的$d(x_i,y_j)$排列起来，用矩阵表示，得到失真矩阵
  $$
  \vec{d}=\left[
  \begin{matrix}
  d(a_1,b_1)&d(a_1,b_2)&\cdots &d(a_1,b_m)\\
  a(a_2,b_1)&d(a_2,b_2)&\cdots& d(a_2,b_m)\\
  \vdots&\vdots& &\vdots\\
  d(a_n,b_1)&d(a_n,b_2)&\cdots&d(a_n,b_m)-0
  \end{matrix}
  \right]
  $$
  称$\vec{d}$为失真矩阵

常见的失真函数有四种

- 均方失真：$d(x_i,y_j)=(x_i-y_j)^2$
- 绝对失真：$d(x_i,y_j)=|x_i-y_j|$
- 相对失真：$d(x_i,y_j)=|x_i-y_j|/|x_i|$
- 误码失真：$d(x_i,y_j)=\delta(x_i,y_j)=\begin{cases}0,x_i=y_j\\1,其他\end{cases}$
- 前三种失真函数适用于**连续信源**，最后一个误码失真适用于**离散信源**

失真函数的定义推广到序列编码，如果离散信源输出符号序列$X=(X_1,X_2,\cdots,X_L)$，其中L长符号序列样值$x_i=(x_{i_1},x_{i_2},\cdots,x_{i_L})$，经信源编码后，输出符号序列$\vec{Y}=(Y_1,Y_2,\cdots,Y_L)$，其中L长符号序列样值$y_j=(y_{j_1},y_{j_2},\cdots,y_{j_L})$

- 则失真函数定义为$d_L(\vec{x_i},\vec{y_j})=\frac{1}{L}\sum_{l=1}^{L}{d(x_{i_l},y_{j_l})}$
  - 其中$d(x_{i_l},y_{j_l})$是当信源输出L长符号样值$\vec{x_i}$中的第$l$个符号$x_{i_l}$，经编码后输出L长符号样值$\vec{y_j}$中的第$l$个符号$y_{j_l}$时的失真函数
- 由于$x_i$和$y_j$都是随机变量，所有失真函数$d(x_i,y_j)$也是随机变量。要分析整个信源的失真大小，就需要用器数学期望或统计平均值表示，将失真函数的数学期望称为**平均失真**，记为
  - $\overline{D}=\sum_{i=1}^{n}\sum_{j=1}^{m}{p(a_i,b_j)d(a_i,b_j)}=\sum_{i=1}^{n}\sum_{j=1}^{m}{p(a_i)p(b_j|a_i)d(a_i,b_j)}$
    - 其中，$p(a_i,b_j),i=1,2,\cdots,n;j=1,2,\cdots,m$是联合分布；$p(a_i)$是信源符号概率分布；$p(b_j|a_i),i=1,2,\cdots,n;j=1,2,\cdots,m$是离散随机变量的失真函数。平均失真$\overline{D}$是对给定信源分布$p(a_i)$在经过某一种转移概率分布为$p(b_j|a_i)$的有失真信源编码器后产生失真的总体度量
- 对于连续随机变量定义的平均失真函数
  - $\int_{-\infty}^{\infty}\int_{-\infty}^{\infty}{p_{X,Y}(x,y)d(x,y)dxdy}$
    - 其中，$p_{X,Y}(x,y)$是连续随机变量的联合概率密度；$d(x,y)$是连续随机变量的失真函数
- 对于L长序列编码情况，平均失真为
  - $D_L=\frac{1}{L}\sum_{l=1}^{L}{E[d(x_{i_l},y_{j_l})]}=\frac{1}{L}\sum_{l=1}^{L}{\overline{D_l}}$
    - 其中，$\overline{D_l}$是第$l$个符号的平均失真

#### 4.1.2 信息率失真函数$R(D)$

假设将通过信源编码器的过程等效为信源发送的符号经过假象信道的过程，则信源X经过有失真的信源编码器输出Y，基于这个假设研究限失真信源编码问题

信源编码器的目的是使编码后所需的信息传输率R尽量小，然而R越小，引起的平均失真D就越大，给出一个失真的限制值$D$，在满足平均失真

- $$
  \overline{D}\leq D
  $$

  的条件下，选择一种编码方式使信息率R尽可能小。信息率R就是所需输出的有关信源X的信息量

将此问题对应到信道，即为接收端Y需要获得的有关X的信息量，也就使互信息$I(X;Y)$。这样，选择信源编码方式的问题就变成了选择假象信道问题，符号转移概率$p(y_j|x_i)$就对应信道转移概率

根据**平均失真**的定义式，平均失真信源由信源分布$p(x_i)$、假象信道的转移概率$p(y_j|x_i)$和失真函数$d(x_i,y_j)$决定，若$p(x_i)$和$d(x_i,y_j)$已定，则给出满足下列式条件的所有转移概率分布$p_{ij}$，它们构成了一个信道集合$P_D$

- $P_D=\{p(b_j|a_i);\overline{D}\leq D\;i=1,2,\cdots,n;j=1,2,\cdots,m\}$称为**D允许试验信道**

由于互信息取决于信源分布和信道转移概率分布，当$p(X_i)$一定时，互信息$I$是关于$p(y_j|x_i)$的U型凸函数，存在极小值。因而在上述允许信道$P_D$中，可以寻找一种信道$p_{ij}$，使给定的信源$p(x_i)$经过次信道传输后，互信息$I(X;Y)$达到最小。该最小的互信息就称为**信息率失真函数$R(D)$**，即

- $R(D)=\min_{P_D}{I(X;Y)}=\min_{P_{ij}\in P_D}{\sum_{i=1}^{n}\sum_{j=1}^{m}{p(a_i)p(b_j|a_i)\log{\frac{p(b_j|a_i)}{p(b_j)}}}}$
  - 其中，$p(a_i),i=1,2,\cdots,n$是信源符号概率分布；$p(b_j|a_i),i=1,2,\cdots,n,j=1,2,\cdots,m$是转移概率分布；$p(b_j),j=1,2,\cdots,m$是接收端收到符号概率分布
  - 由互信息的关系式$I(X;Y)=H(Y)-H(Y|X)=H(X)-H(X|Y)$，可理解为互信息式信源发出的信息量$H(X)$与在噪声干预条件下消失的信息量$H(Y|X)$之差

信息失真率函数的物理意义是：对于给定信源，在平均失真不超过失真限度D的条件下，信息率容许压缩的最小值$R(D)$

#### 4.1.3 信息率失真函数的性质

1. $R(D)$函数的定义域

**$D_{min}和R(D_{min})$** 

